<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >	
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
  @import url(https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300);
    /* Color scheme stolen from Sergey Karayev */
    a {
    /*color: #b60a1c;*/
    color: #1772d0;
    /*color: #bd0a36;*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Roboto', sans-serif;
    font-size: 15px;
    font-weight: 300;
    }
    strong {
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    /*font-family: 'Avenir Next';*/
    font-size: 15px;
    font-weight: 400;
    }
    heading {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 24px;
    font-weight: 400;
    }
    papertitle {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 15px;
    font-weight:500;
    }
    name {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    font-weight: 400;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 140px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="media/icon.png">
  <title>TaoPu - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="script/functions.js"></script>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Tao PU (蒲韬)</name>
        </p>
        <p>
          I am currently a Ph.D. student from the School of Computer Science and Engineering at Sun Yat-sen University. I am grateful to join the <a href="http://www.sysu-hcp.net/">HCP Lab</a> and be advised by Prof. <a href="http://www.linliang.net/">Liang Lin</a>. Before that, I received my Bachelor’s Degree from Sun Yat-sen University in 2020.
        </p> 
        <p>
          I’m broadly interested in visual understanding. The goal of my research is to build general-purpose agents that can abstract the environment from a human-oriented perspective and have versatile motor skills in challenging scenarios.
        </p>  
        <p align=center>
          <a href="mailto:putao537@gmail.com">Email</a> &nbsp|&nbsp
          <a href="files/resume.pdf">CV</a> &nbsp|&nbsp
          <a href="https://github.com/putao537">GitHub</a> &nbsp|&nbsp
          <a href="https://scholar.google.com/citations?user=cBRGYzYAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
          <a href="https://www.linkedin.com/in/tao-pu-7353a0180/"> LinkedIn</a>
        </p>
        </td>
        <td width="33%">
          <img src="media/profile.jpg" width="250" alt="headshot">
          <!--<div class="one">
          <div class="two" id="headshot_image"><img src="media/color_headshot.png" width="250" alt="headshot"></div>
          <img src="media/bw_headshot.png" width="250" alt="headshot">
          </div>
          <script type="text/javascript">
          function headshot_start() {
          document.getElementById('headshot_image').style.opacity = "1";
          }
          function headshot_stop() {
          document.getElementById('headshot_image').style.opacity = "0";
          }
          filters_stop()
          </script>-->
        </td>
        <!--<td width="33%">
        <img src="media/bw_headshot.png" width="250">
        <img src="media/color_headshot.png" width="250">
        </td>-->
      </tr>
      <!-- <td width="10%"><a href="adsc.illinois.edu"><img src="media/adsc_logo.png" width="100"></a></td>
      <td width="10%"><a href="https://www.inria.fr/en/"><img src="media/inria_logo.jpg" width="100"></a></td>
      <td width="10%"><a href="https://vision.in.tum.de"><img src="media/tum_logo.jpg" width="100"></a></td>
      <td width="10%"><a href="https://www.vibot.org"><img src="media/vibot_logo_transparent.png" width="50"></a></td> -->
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <heading>News</heading>
            <ul>
              <li><strong>09/2023</strong> Join <a href="https://pku.ai/"> PKU CoRe Lab</a> as a visiting student! Worked with <a href="https://jiemingcui.github.io/">Jieming Cui</a>, and advised by Dr. <a href="https://yzhu.io/"> Yixin Zhu</a>.</li>
              <!-- 
              <li><strong>07/2024</strong> Our paper <a href="https://segment3d.github.io/"><strong>Segment3D</strong></a> is accepted to ECCV 2024! Also, I will be co-organizing two workshops: <a href="https://focus-workshop.github.io/">Foundation Models Creators Meet Users (FOCUS)</a> and <a href="https://opensun3d.github.io/">Open-Vocabulary 3D Scene Understanding (OpenSUN3D)</a>.</li>
              <li><strong>05/2024</strong> <b><span style="color:#c20000;">Career Update</span></b>: I start working as a research scientist at <a href="https://deepmind.google/"><strong>Google DeepMind</strong></a>!</li>
              <li><strong>03/2024</strong> Our papers <a href="https://rwn17.github.io/nerf-on-the-go/"><strong>NeRF <em>On-the-go</em></strong></a> and <a href="https://neural-edge-map.github.io/"><strong>3D Neural Edge Reconstruction</strong></a> are accepted to <strong>CVPR 2024</strong>! Congrats on the successful master theses of my amazing students at ETH Zurich, <a href="https://scholar.google.com/citations?user=A6d9VTAAAAAJ">Lei Li</a> and <a href="https://github.com/rwn17">Weining Ren</a>!</li>
              <li><strong>03/2024</strong> <a href="https://nicer-slam.github.io/"><strong>NICER-SLAM</strong></a> received the <img src="media/logo_award.png" width="20"><strong><span style="color:#c20000;">Best Paper Honorable Mention Award</span></strong> at <strong>3DV 2024</strong>! Congrats to all co-authors, especially <a href="https://zzh2000.github.io/">Zihan</a>, who started this project during his bachelor and did such a wonderful job!!</li>
              <li><strong>03/2024</strong> Invited to give a talk on <a href="files/talk_hku.pdf">2D Magic in a 3D World</a> at Imperial College London and the University of Hong Kong. </li>
              <li><strong>11/2023</strong> <strong>I successfully defended my PhD</strong>! [<a href="files/Songyou_PhD_Thesis.pdf">Thesis</a>][<a href="files/songyou_phd_defense.pdf">Defense Slides</a>]
              <li><strong>10/2023</strong> Our papers <img src="media/logo_nicer.png" width="20"><a href="https://nicer-slam.github.io"> <strong>NICER-SLAM</strong></a> and <a href="https://l1346792580123.github.io/nccsfs/"><strong>FastHuman</strong></a> are accepted to 3DV 2024.
              <li><strong>07/2023</strong> I served as an Area Chair at <a href="https://3dvconf.github.io/2024/area-chairs/">3DV 2024</a>.
              <li><strong>07/2023</strong> I received the <img src="media/logo_award.png" width="20"><a href="https://twitter.com/GMFarinella/status/1679889056266694666"><strong>Best Presentation Award</strong></a> at <a href="https://iplab.dmi.unict.it/icvss2023/">ICVSS 2023</a>!</li>
              <li><strong>07/2023</strong> Our paper <a href="https://primecai.github.io/diffdreamer">DiffDreamer</a> is accepted to ICCV 2023! Congrats Shengqu on a successful master thesis!
              <li><strong>07/2023</strong> Invited to give a 90-min lecture at <a href="https://sgp2023.github.io/program/">SGP 2023</a> graduate school in <a href="files/talk_sgp.pdf">neural explicit-implicit representations!</a></li>
              -->
              <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
              <div id="old_news" style="display: none;">
              
            </div></div>
            </ul>
        </td>
      </tr>

      <!-- Research -->
      <tr>
        <td width="100%" valign="middle">
          <heading>Selected Publications</heading> <br>
          Please see <a href="https://scholar.google.com/citations?user=cBRGYzYAAAAJ&hl=en">Google Scholar</a> for more recent works and arXiv papers. <br>
          * denotes <strong>equal contribution</strong>,  &#8224; denotes <strong>corresponding author</strong>.
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >

        <tr onmouseout="TIP2024_STKET_stop()" onmouseover="TIP2024_STKET_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'TIP2024_STKET'>
              <img src='media/TIP2024_STKET.png' width="160" height="124"></div>
            <img src='media/TIP2024_STKET.png' width="160" height="124"></div>
            <script type="text/javascript">
            function TIP2024_STKET_start() { 
            document.getElementById('TIP2024_STKET').style.opacity = "1";
            }
            function TIP2024_STKET_stop() { 
            document.getElementById('TIP2024_STKET').style.opacity = "0"; 
            }
            TIP2024_STKET_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle>
                  Spatial–Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation
                </papertitle>
              </a>
          <br>
              <strong>Tao Pu*</strong>, Tianshui Chen* &#8224;, Hefeng Wu, Yongyi Lu, Liang Lin
          <br>
              <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2024
            <br>
            <a href="https://ieeexplore.ieee.org/document/10375886">Paper</a> |
            <a href="https://github.com/HCPLab-SYSU/STKET">Code</a> |
            <a href="bib/TIP2024_STKET.bib" target="_blank">Cite</a>
            <p></p>
            <strong>TL;DR:</strong> A video scene graph generation approach that incorporates the prior spatial-temporal knowledge to learn better representations.
            <p></p>
          </td>
        </tr>
    
        <tr onmouseout="IJCV2024_HST_stop()" onmouseover="IJCV2024_HST_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'IJCV2024_HST'>
              <img src='media/IJCV2024_HST.png' width="160" height="124"></div>
            <img src='media/IJCV2024_HST.png' width="160" height="124"></div>
            <script type="text/javascript">
            function IJCV2024_HST_start() { 
            document.getElementById('IJCV2024_HST').style.opacity = "1";
            }
            function IJCV2024_HST_stop() { 
            document.getElementById('IJCV2024_HST').style.opacity = "0"; 
            }
            IJCV2024_HST_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle>
                  Heterogeneous Semantic Transfer for Multi-label Recognition with Partial Labels
                </papertitle>
              </a>
          <br>
              Tianshui Chen*&#8224;, <strong>Tao Pu*</strong>, Lingbo Liu, Yukai Shi, Zhijing Yang, Liang Lin
          <br>
              <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2024
            <br>
            <a href="https://link.springer.com/article/10.1007/s11263-024-02127-2?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=nonoa_20240715&utm_content=10.1007%2Fs11263-024-02127-2#citeas">Paper</a> |
            <a href="https://github.com/HCPLab-SYSU/HCP-MLR-PL">Code</a> |
            <a href="bib/IJCV2024_HST.bib" target="_blank">Cite</a> |
            <a href="https://zhuanlan.zhihu.com/p/684478294">知乎</a>
            <p></p>
            <strong>TL;DR:</strong> A weakly-supervised MLR approach that explores heterogeneous semantics inherently within multi-label images.
            <p></p>
          </td>
        </tr>

        <tr onmouseout="TPAMI2022_CDFER_stop()" onmouseover="TPAMI2022_CDFER_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'TPAMI2022_CDFER'>
              <img src='media/TPAMI2022_CDFER.png' width="160" height="124"></div>
            <img src='media/TPAMI2022_CDFER.png' width="160" height="124"></div>
            <script type="text/javascript">
            function TPAMI2022_CDFER_start() { 
            document.getElementById('TPAMI2022_CDFER').style.opacity = "1";
            }
            function TPAMI2022_CDFER_stop() { 
            document.getElementById('TPAMI2022_CDFER').style.opacity = "0"; 
            }
            TPAMI2022_CDFER_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle>
                  Cross-Domain Facial Expression Recognition: A Unified Evaluation Benchmark and Adversarial Graph Learning
                </papertitle>
              </a>
          <br>
              Tianshui Chen*, <strong>Tao Pu*</strong>, Hefeng Wu&#8224;, Yuan Xie, Lingbo Liu, Liang Lin
          <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2022
            <br>
            <a href="https://ieeexplore.ieee.org/document/9628054">Paper</a> |
            <a href="https://github.com/HCPLab-SYSU/CD-FER-Benchmark">Code</a> |
            <a href="bib/TPAMI2022_CDFER.bib" target="_blank">Cite</a> |
            <a href="https://zhuanlan.zhihu.com/p/353606619">知乎</a>
            <p></p>
            <strong>TL;DR:</strong> One of the largest CD-FER evaluation benchmarks that unifies the source/target datasets and feature extractors for existing algorithms.
            <p></p>
          </td>
        </tr>
  
  </table>
   
  <!-- Invited Talks --> 
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;">
    <heading>Invited Talks</heading>

    <br><br><br>

    <!--
    <tr onmouseout="hku_stop()" onmouseover="hku_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'hku_shape'>
        <img src='media/talk_hku_teaser.jpg' width="180" height="100"></div>
        <img src='media/talk_hku_teaser.jpg' width="180" height="100"></div>
        </div>
        <script type="text/javascript">
        function hku_start() { 
        document.getElementById('hku_shape').style.opacity = "1";
        }
        function hku_stop() { 
        document.getElementById('hku_shape').style.opacity = "0"; 
        }
        hku_stop()
        </script>
      </td>
      <td valign="top" width="75%">
          <a href="files/talk_hku.pdf">
            <papertitle>2D Magic in a 3D World</papertitle></a>
      <br>
          <em><strong>Imperial College London</strong></em>, hosted by <a href="https://www.doc.ic.ac.uk/~ajd/">Andrew Davison</a>, 2024<br>
          <em><strong>Czech Technical University (CTU)</strong></em>, hosted by <a href="https://tsattler.github.io/">Torsten Sattler</a>, 2024<br>
          <em><strong>The University of Hong Kong (HKU)</strong></em>, hosted by <a href="https://www.kaihan.org/">Kai Han</a>, 2024
      <br>
        <a href="files/talk_hku.pdf">slides</a>
      </td>
    </tr>
    -->  
  </table>
      

  <!-- Academic Services -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <heading>Academic Services</heading>
      <tr>
        <td>
          
          <ul>
              <!-- <li> <strong>Publicity Chair</strong>: 3DV'25<br> -->
              <!-- <li> <strong>Area Chair</strong>: 3DV'24<br> -->
              <!-- <li> <strong>Workshop Organizer</strong>: <a href="https://opensun3d.github.io/">OpenSUN3D</a> at ICCV'23 (<a href="https://opensun3d.github.io/index_iccv23.html">1st</a>), CVPR'24 (<a href="https://opensun3d.github.io/index_cvpr2024.html">2nd</a>), and ECCV'24 (<a href="https://opensun3d.github.io/index.html">3rd</a>), <a href="https://focus-workshop.github.io/">FOCUS</a> at ECCV'24<br> -->
              <li> <strong>Conference Reviewer</strong>: CVPR, ICLR, NeurIPS, ICML, IJCAI, ACM MM<br>
              <li> <strong>Journal Reviewer</strong>: TPAMI, TNNLS, TKDE
          </ul>
        </td>
      </tr>
  </table>


    </td>
    </tr>
  </table>
  </body>
</html>
<!--  -->
